# -*- coding: utf-8 -*-
"""Arctic Sea Ice Data Description & Preparation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InqcFV5NmfLP_NocNJAyvFa-pndYHy_v
"""

import pandas as pd
import matplotlib.pyplot as plt
plt.style.use("fivethirtyeight")
from darts import TimeSeries
from darts.models import NBEATSModel
from darts.dataprocessing.transformers import Scaler
from darts.metrics import r2_score, rmse, mae
import numpy as np
import time
#%%
def display_forecast(pred_series, ts_transformed, forecast_type, chartname, start_date=None, ):
    plt.figure(figsize=(15, 8))
    if start_date:
        ts_transformed = ts_transformed.drop_before(start_date)
    ts_transformed.univariate_component(0).plot(label="actual")
    pred_series.plot(label=("historic " + forecast_type + " forecasts"))
    plt.title(chartname+
        "\nR2: {}".format(r2_score(ts_transformed.univariate_component(0), pred_series))
        +"\nRMSE: {}".format(rmse(ts_transformed.univariate_component(0), pred_series))    
        +"\nMAE: {}".format(mae(ts_transformed.univariate_component(0), pred_series))    
    )
    plt.legend()
#%%
df = pd.read_csv("https://raw.githubusercontent.com/SN129090/NU-Climate-Data-Analytics-Project/main/Baffin%20Sea%20Ice%20Extent.csv")
df_beau = pd.read_csv("https://raw.githubusercontent.com/SN129090/NU-Climate-Data-Analytics-Project/main/Beaufort%20Sea%20Ice%20Extent.csv")
df_canarc = pd.read_csv("https://raw.githubusercontent.com/SN129090/NU-Climate-Data-Analytics-Project/main/CanArch%20Sea%20Ice%20Extent.csv")
df_hudson = pd.read_csv("https://raw.githubusercontent.com/SN129090/NU-Climate-Data-Analytics-Project/main/Hudson%20Sea%20Ice%20Extent.csv")
#%%
### Data preparation - converting the matrix of values into a single column for each dataset, 
### Creating date column and assigning as index

df['day'] = (df['day']).astype(str)
df['Month-Day'] = pd.concat([df['month'] + "-" + df['day']])
df_beau['day'] = (df_beau['day']).astype(str)
df_beau['Month-Day'] = pd.concat([df_beau['month'] + "-" + df_beau['day']])
df_canarc['day'] = (df_canarc['day']).astype(str)
df_canarc['Month-Day'] = pd.concat([df_canarc['month'] + "-" + df_canarc['day']])
df_hudson['day'] = (df_hudson['day']).astype(str)
df_hudson['Month-Day'] = pd.concat([df_hudson['month'] + "-" + df_hudson['day']])


baffin_melt = df.melt(id_vars='Month-Day', var_name='Year', value_name="BAFFIN SEA ICE EXTENT")
baffin_melt['Year'] = baffin_melt['Year'].astype(str)
baffin_melt = baffin_melt[baffin_melt.Year != 'month']
baffin_melt = baffin_melt[baffin_melt.Year != 'day']
baffin_melt['Date'] = pd.concat([baffin_melt['Month-Day']+"-"+baffin_melt['Year']])
baffin_melt = baffin_melt.dropna(axis=0)

beau_melt = df_beau.melt(id_vars='Month-Day', var_name='Year', value_name="BEAUFORT SEA ICE EXTENT")
beau_melt['Year'] = beau_melt['Year'].astype(str)
beau_melt = beau_melt[beau_melt.Year != 'month']
beau_melt = beau_melt[beau_melt.Year != 'day']
beau_melt['Date'] = pd.concat([beau_melt['Month-Day']+"-"+beau_melt['Year']])
beau_melt = beau_melt.dropna(axis=0)

canarc_melt = df_canarc.melt(id_vars='Month-Day', var_name='Year', value_name="CAN. ARCH. SEA ICE EXTENT")
canarc_melt['Year'] = canarc_melt['Year'].astype(str)
canarc_melt = canarc_melt[canarc_melt.Year != 'month']
canarc_melt = canarc_melt[canarc_melt.Year != 'day']
canarc_melt['Date'] = pd.concat([canarc_melt['Month-Day']+"-"+canarc_melt['Year']])
canarc_melt = canarc_melt.dropna(axis=0)

hudson_melt = df_hudson.melt(id_vars='Month-Day', var_name='Year', value_name="HUDSON BAY SEA ICE EXTENT")
hudson_melt['Year'] = hudson_melt['Year'].astype(str)
hudson_melt = hudson_melt[hudson_melt.Year != 'month']
hudson_melt = hudson_melt[hudson_melt.Year != 'day']
hudson_melt['Date'] = pd.concat([hudson_melt['Month-Day']+"-"+hudson_melt['Year']])
hudson_melt = hudson_melt.dropna(axis=0)

baffin_melt['Date'] = pd.to_datetime(baffin_melt['Date'], format='%B-%d-%Y')
baffin_melt['Date']
baffin_melt.set_index('Date', inplace =True)

beau_melt['Date'] = pd.to_datetime(beau_melt['Date'], format='%B-%d-%Y')
beau_melt['Date']
beau_melt.set_index('Date', inplace =True)

canarc_melt['Date'] = pd.to_datetime(canarc_melt['Date'], format='%B-%d-%Y')
canarc_melt['Date']
canarc_melt.set_index('Date', inplace =True)

hudson_melt['Date'] = pd.to_datetime(hudson_melt['Date'], format='%B-%d-%Y')
hudson_melt['Date']
hudson_melt.set_index('Date', inplace =True)
#%%
# Restoring month from date
baffin_melt['month'] = [d.strftime('%b') for d in baffin_melt.index]
beau_melt['month'] = [d.strftime('%b') for d in beau_melt.index]
canarc_melt['month'] = [d.strftime('%b') for d in canarc_melt.index]
hudson_melt['month'] = [d.strftime('%b') for d in hudson_melt.index]
#%%
from statsmodels.tsa.stattools import adfuller
adf, pvalue, usedlag_, nobs_, critical_values_, icbest_ = adfuller(baffin_melt["BAFFIN SEA ICE EXTENT"])
print("pvalue = ", pvalue, " if above 0.05, data is not stationary")
#%%
adf, pvalue, usedlag_, nobs_, critical_values_, icbest_ = adfuller(beau_melt["BEAUFORT SEA ICE EXTENT"])
print("pvalue = ", pvalue, " if above 0.05, data is not stationary")
#%%
adf, pvalue, usedlag_, nobs_, critical_values_, icbest_ = adfuller(canarc_melt["CAN. ARCH. SEA ICE EXTENT"])
print("pvalue = ", pvalue, " if above 0.05, data is not stationary")
#%%
adf, pvalue, usedlag_, nobs_, critical_values_, icbest_ = adfuller(hudson_melt["HUDSON BAY SEA ICE EXTENT"])
print("pvalue = ", pvalue, " if above 0.05, data is not stationary")
#%%
# Reduce to monthly
baff_m = baffin_melt['BAFFIN SEA ICE EXTENT'].groupby(pd.Grouper(freq="M")).mean()
beau_m = beau_melt['BEAUFORT SEA ICE EXTENT'].groupby(pd.Grouper(freq="M")).mean()
canarc_m = canarc_melt['CAN. ARCH. SEA ICE EXTENT'].groupby(pd.Grouper(freq="M")).mean()
hudson_m = hudson_melt['HUDSON BAY SEA ICE EXTENT'].groupby(pd.Grouper(freq="M")).mean()
baff_m.drop(index=baff_m.index[0], axis=0, inplace=True)
baff_m.drop(index=baff_m.index[0], axis=0, inplace=True)
#%%
#Preparing data for n-beats model and normalizing using min-max scaler
baff_d = baffin_melt.reset_index()
scaler = Scaler()
baf_d_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            baff_d, time_col="Date", value_cols="BAFFIN SEA ICE EXTENT")).astype(np.float32)
baf_d_series.plot()
plt.title("Baffin Sea Ice Daily")
#%% - Beaufort Sea
beau_d = beau_melt.reset_index()
beau_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            beau_d, time_col="Date", value_cols="BEAUFORT SEA ICE EXTENT")).astype(np.float32)
beau_series.plot()
plt.title("Beaufort Sea Ice Daily")
#%% - Canadian Archipelago
canarc_d = canarc_melt.reset_index()
canarc_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            canarc_d, time_col="Date", value_cols="CAN. ARCH. SEA ICE EXTENT")).astype(np.float32)
canarc_series.plot()
plt.title("Canadian Archipelago Sea Ice Daily")
#%% - Hudson Bay
hud_d = hudson_melt.reset_index()
hud_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
           hud_d, time_col="Date", value_cols="HUDSON BAY SEA ICE EXTENT")).astype(np.float32)
hud_series.plot()
plt.title("Hudson Bay Sea Ice Daily")
#%% N-BEATS Generic Architecture Model
model_nbeats = NBEATSModel(
    input_chunk_length=30,
    output_chunk_length=7,
    generic_architecture=True,
    num_stacks=10,
    num_blocks=1,
    num_layers=4,
    layer_widths=512,
    n_epochs=100,
    nr_epochs_val_period=1,
    batch_size=800,
    model_name="nbeats_run",
)
#%% N-BEATS Interpretable Architecture Model
int_model_nbeats = NBEATSModel(
    input_chunk_length=30,
    output_chunk_length=7,
    generic_architecture=False,
    num_blocks=3,
    num_layers=4,
    layer_widths=512,
    n_epochs=100,
    nr_epochs_val_period=1,
    batch_size=800,
    model_name="nbeats_interpretable_run",
)
#%%
baf_d_train, baf_d_val = baf_d_series.split_after(pd.Timestamp("20070731"))
beau_train, beau_val = beau_series.split_after(pd.Timestamp("20070731"))
canarc_train, canarc_val = canarc_series.split_after(pd.Timestamp("20070731"))
hud_train, hud_val = hud_series.split_after(pd.Timestamp("20070731"))
#%%
#NBEATS MODEL - BAFFIN
ba_mod_start = time.time()
baf_d_model = model_nbeats.fit(baf_d_train, val_series=baf_d_val, verbose=True)
ba_mod_stop = time.time()
ba_pred_start = time.time()
pred_d_series = baf_d_model.historical_forecasts(
    baf_d_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
ba_pred_stop = time.time()
display_forecast(pred_d_series, baf_d_series, "5-day","N-BEATS Generic Model - Baffin", start_date=pd.Timestamp("20070731"))
ba_mod_time = ba_mod_stop - ba_mod_start
ba_pred_time = ba_pred_stop - ba_pred_start
print("Train Time {}".format(ba_mod_time)+"s"+ "\nPrediction Time: {}".format(ba_pred_time)+"s")
#%%
#NBEATS MODEL - BAFFIN Interperetable
ba_i_mod_start = time.time()
baf_i_model = int_model_nbeats.fit(baf_d_train, val_series=baf_d_val, verbose=True)
ba_i_mod_stop = time.time()
ba_i_pred_start = time.time()
pred_i_series = baf_i_model.historical_forecasts(
    baf_d_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
ba_i_pred_stop = time.time()
display_forecast(pred_i_series, baf_d_series, "5-day","N-BEATS Interpretable Model - Baffin", start_date=pd.Timestamp("20070731"))
ba_i_mod_time = ba_i_mod_stop - ba_i_mod_start
ba_i_pred_time = ba_i_pred_stop - ba_i_pred_start
print("Train Time {}".format(ba_mod_time)+"s"+ "\nPrediction Time: {}".format(ba_pred_time)+"s")
#%%
#NBEATS MODEL - Beaufort Sea - Generic Model
be_mod_start = time.time()
beau_model = model_nbeats.fit(beau_train, val_series=beau_val, verbose=True)
be_mod_stop = time.time()
be_pred_start = time.time()
pred_beau_series = beau_model.historical_forecasts(
    beau_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
be_pred_stop = time.time()
display_forecast(pred_beau_series, beau_series, "5-day","N-BEATS Generic Model - Beaufort Sea", start_date=pd.Timestamp("20070731"))
be_mod_time = be_mod_stop - be_mod_start
be_pred_time = be_pred_stop - be_pred_start
print("Train Time {}".format(be_mod_time)+"s"+ "\nPrediction Time: {}".format(be_pred_time)+"s")
#%%
#NBEATS MODEL - Beaufort - Interperetable Model
be_i_mod_start = time.time()
beau_i_model = int_model_nbeats.fit(beau_train, val_series=beau_val, verbose=True)
be_i_mod_stop = time.time()
be_i_pred_start = time.time()
pred_beau_i_series = beau_i_model.historical_forecasts(
    beau_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
be_i_pred_stop = time.time()
display_forecast(pred_beau_i_series, beau_series, "5-day","N-BEATS Interpretable Model - Beaufort Sea", start_date=pd.Timestamp("20070731"))
be_i_mod_time = be_i_mod_stop - be_i_mod_start
be_i_pred_time = be_i_pred_stop - be_i_pred_start
print("Train Time {}".format(be_mod_time)+"s"+ "\nPrediction Time: {}".format(be_pred_time)+"s")
#%%
#NBEATS MODEL - Canadian Archipelago Sea
ca_mod_start = time.time()
canarc_model = model_nbeats.fit(canarc_train, val_series=canarc_val, verbose=True)
ca_mod_stop = time.time()
ca_pred_start = time.time()
pred_canarc_series = canarc_model.historical_forecasts(
    canarc_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
ca_pred_stop = time.time()
display_forecast(pred_canarc_series, canarc_series, "5-day","N-BEATS Generic Model - Canadian Archipelago", start_date=pd.Timestamp("20070731"))
ca_mod_time = ca_mod_stop - ca_mod_start
ca_pred_time = ca_pred_stop - ca_pred_start
print("Train Time {}".format(ca_mod_time)+"s"+ "\nPrediction Time: {}".format(ca_pred_time)+"s")
#%%
#NBEATS MODEL - Canadian Archipelago - Interperetable Model
ca_i_mod_start = time.time()
canarc_i_model = int_model_nbeats.fit(canarc_train, val_series=canarc_val, verbose=True)
ca_i_mod_stop = time.time()
ca_i_pred_start = time.time()
pred_canarc_i_series = canarc_i_model.historical_forecasts(
    canarc_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
ca_i_pred_stop = time.time()
display_forecast(pred_canarc_i_series, canarc_series, "5-day","N-BEATS Interpretable Model - Canadian Archipelago", start_date=pd.Timestamp("20070731"))
ca_i_mod_time = ca_i_mod_stop - ca_i_mod_start
ca_i_pred_time = ca_i_pred_stop - ca_i_pred_start
print("Train Time {}".format(ca_mod_time)+"s"+ "\nPrediction Time: {}".format(ca_pred_time)+"s")
#%%
#NBEATS MODEL - Hudson Bay
hb_mod_start = time.time()
hud_model = model_nbeats.fit(hud_train, val_series=hud_val, verbose=True)
hb_mod_stop = time.time()
hb_pred_start = time.time()
pred_hud_series = hud_model.historical_forecasts(
    hud_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
hb_pred_stop = time.time()
display_forecast(pred_hud_series, hud_series, "5-day","N-BEATS Generic Model - Hudson Bay", start_date=pd.Timestamp("20070731"))
hb_mod_time = hb_mod_stop - hb_mod_start
hb_pred_time = hb_pred_stop - hb_pred_start
print("Train Time {}".format(hb_mod_time)+"s"+ "\nPrediction Time: {}".format(hb_pred_time)+"s")
#%%
#NBEATS MODEL - Hudson Bay - Interpretable Model
hb_i_mod_start = time.time()
hud_i_model = int_model_nbeats.fit(hud_train, val_series=hud_val, verbose=True)
hb_i_mod_stop = time.time()
hb_i_pred_start = time.time()
pred_hud_i_series = hud_i_model.historical_forecasts(
    hud_series,
    start=pd.Timestamp("20070731"),
    forecast_horizon=7,
    stride=5,
    retrain=False,
    verbose=True,
)
hb_i_pred_stop = time.time()
display_forecast(pred_hud_i_series, hud_series, "5-day","N-BEATS Interpretable Model - Hudson Bay", start_date=pd.Timestamp("20070731"))
hb_i_mod_time = hb_i_mod_stop - hb_i_mod_start
hb_i_pred_time = hb_i_pred_stop - hb_i_pred_start
print("Train Time {}".format(hb_mod_time)+"s"+ "\nPrediction Time: {}".format(hb_pred_time)+"s")
#%%
# QUARTERLY YEAR-OVER-YEAR FORECASTING
baf_q = baffin_melt['BAFFIN SEA ICE EXTENT'].groupby(pd.Grouper(freq="q")).mean()
baf_q = baf_q.reset_index()
scaler = Scaler()
baf_q_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            baf_q, time_col="Date", value_cols="BAFFIN SEA ICE EXTENT")).astype(np.float32)
baf_q_train, baf_q_val = baf_q_series.split_after(pd.Timestamp("20070630"))
ba_q_mod_start = time.time()
baf_q_model = model_nbeats.fit(baf_q_train, val_series=baf_q_val, verbose=True)
ba_q_mod_stop = time.time()
ba_q_pred_start = time.time()
pred_q_series = baf_q_model.historical_forecasts(
    baf_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
ba_q_pred_stop = time.time()
display_forecast(pred_q_series, baf_q_series, "3-month", "N-BEATS Generic Model - Baffin", start_date=pd.Timestamp("20070630"))
ba_q_mod_time = ba_q_mod_stop - ba_q_mod_start
ba_q_pred_time = ba_q_pred_stop - ba_q_pred_start
print("Train Time {}".format(ba_q_mod_time)+"s"+ "\nPrediction Time: {}".format(ba_q_pred_time)+"s")
#%%
ba_q_int_mod_start = time.time()
baf_q_int_model = int_model_nbeats.fit(baf_q_train, val_series=baf_q_val, verbose=True)
ba_q_int_mod_stop = time.time()
ba_q_int_pred_start = time.time()
pred_q_int_series = baf_q_int_model.historical_forecasts(
    baf_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
ba_q_int_pred_stop = time.time()
display_forecast(pred_q_int_series, baf_q_series, "3-month", "N-BEATS Interpretable Model - Baffin", start_date=pd.Timestamp("20070630"))
ba_q_int_mod_time = ba_q_int_mod_stop - ba_q_int_mod_start
ba_q_int_pred_time = ba_q_int_pred_stop - ba_q_int_pred_start
print("Train Time {}".format(ba_q_int_mod_time)+"s"+ "\nPrediction Time: {}".format(ba_q_int_pred_time)+"s")
#%%
# Beaufort Sea Quarterly
beau_q = beau_melt['BEAUFORT SEA ICE EXTENT'].groupby(pd.Grouper(freq="q")).mean()
beau_q = beau_q.reset_index()
scaler = Scaler()
beau_q_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            beau_q, time_col="Date", value_cols="BEAUFORT SEA ICE EXTENT")).astype(np.float32)
beau_q_train, beau_q_val = beau_q_series.split_after(pd.Timestamp("20070630"))
be_q_mod_start = time.time()
beau_q_model = model_nbeats.fit(beau_q_train, val_series=beau_q_val, verbose=True)
be_q_mod_stop = time.time()
be_q_pred_start = time.time()
pred_beau_q_series = beau_q_model.historical_forecasts(
    beau_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
be_q_pred_stop = time.time()
display_forecast(pred_beau_q_series, beau_q_series, "3-month", "N-BEATS Generic Model - Beaufort Sea", start_date=pd.Timestamp("20070630"))
be_q_mod_time = be_q_mod_stop - be_q_mod_start
be_q_pred_time = be_q_pred_stop - be_q_pred_start
print("Train Time {}".format(be_q_mod_time)+"s"+ "\nPrediction Time: {}".format(be_q_pred_time)+"s")
#%%
be_q_int_mod_start = time.time()
beau_q_int_model = int_model_nbeats.fit(beau_q_train, val_series=beau_q_val, verbose=True)
be_q_int_mod_stop = time.time()
be_q_int_pred_start = time.time()
pred_beau_q_int_series = beau_q_int_model.historical_forecasts(
    beau_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
be_q_int_pred_stop = time.time()
display_forecast(pred_beau_q_int_series, beau_q_series, "3-month", "N-BEATS Interpretable Model - Beaufort Sea", start_date=pd.Timestamp("20070630"))
be_q_int_mod_time = be_q_int_mod_stop - be_q_int_mod_start
be_q_int_pred_time = be_q_int_pred_stop - be_q_int_pred_start
print("Train Time {}".format(be_q_int_mod_time)+"s"+ "\nPrediction Time: {}".format(be_q_int_pred_time)+"s")
#%%
# Canadian Archipelago Quarterly
ca_q = canarc_melt['CAN. ARCH. SEA ICE EXTENT'].groupby(pd.Grouper(freq="q")).mean()
ca_q = ca_q.reset_index()
scaler = Scaler()
ca_q_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            ca_q, time_col="Date", value_cols="CAN. ARCH. SEA ICE EXTENT")).astype(np.float32)
ca_q_train, ca_q_val = ca_q_series.split_after(pd.Timestamp("20070630"))
ca_q_mod_start = time.time()
ca_q_model = model_nbeats.fit(ca_q_train, val_series=ca_q_val, verbose=True)
ca_q_mod_stop = time.time()
ca_q_pred_start = time.time()
pred_ca_q_series = ca_q_model.historical_forecasts(
    ca_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
ca_q_pred_stop = time.time()
display_forecast(pred_ca_q_series, ca_q_series, "3-month", "N-BEATS Generic Model - Canadian Archipelago", start_date=pd.Timestamp("20070630"))
ca_q_mod_time = ca_q_mod_stop - ca_q_mod_start
ca_q_pred_time = ca_q_pred_stop - ca_q_pred_start
print("Train Time {}".format(ca_q_mod_time)+"s"+ "\nPrediction Time: {}".format(ca_q_pred_time)+"s")
#%%
ca_q_int_mod_start = time.time()
ca_q_int_model = int_model_nbeats.fit(ca_q_train, val_series=ca_q_val, verbose=True)
ca_q_int_mod_stop = time.time()
ca_q_int_pred_start = time.time()
pred_ca_q_int_series = ca_q_int_model.historical_forecasts(
    ca_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
ca_q_int_pred_stop = time.time()
display_forecast(pred_ca_q_int_series, ca_q_series,"3-month", "N-BEATS Interpretable Model - Canadian Archipelago", start_date=pd.Timestamp("20070630"))
ca_q_int_mod_time = ca_q_int_mod_stop - ca_q_int_mod_start
ca_q_int_pred_time = ca_q_int_pred_stop - ca_q_int_pred_start
print("Train Time {}".format(ca_q_int_mod_time)+"s"+ "\nPrediction Time: {}".format(ca_q_int_pred_time)+"s")
#%%
# Hudson Bay Quarterly

hb_q = hudson_melt['HUDSON BAY SEA ICE EXTENT'].groupby(pd.Grouper(freq="q")).mean()
hb_q = hb_q.reset_index()
scaler = Scaler()
hb_q_series = scaler.fit_transform(
        TimeSeries.from_dataframe(
            hb_q, time_col="Date", value_cols="HUDSON BAY SEA ICE EXTENT")).astype(np.float32)
hb_q_train, hb_q_val = hb_q_series.split_after(pd.Timestamp("20070630"))
hud_q_mod_start = time.time()
hb_q_model = model_nbeats.fit(hb_q_train, val_series=hb_q_val, verbose=True)
hud_q_mod_stop = time.time()
hud_q_pred_start = time.time()
pred_hb_q_series = hb_q_model.historical_forecasts(
    hb_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
hud_q_pred_stop = time.time()
display_forecast(pred_hb_q_series, hb_q_series, "3-month", "N-BEATS Generic Model - Hudson Bay", start_date=pd.Timestamp("20070630"))
hud_q_mod_time = hud_q_mod_stop - hud_q_mod_start
hud_q_pred_time = hud_q_pred_stop - hud_q_pred_start
print("Train Time {}".format(hud_q_mod_time)+"s"+ "\nPrediction Time: {}".format(hud_q_pred_time)+"s")
#%%
hud_q_int_mod_start = time.time()
hb_q_int_model = int_model_nbeats.fit(hb_q_train, val_series=hb_q_val, verbose=True)
hud_q_int_mod_stop = time.time()
hud_q_int_pred_start = time.time()
pred_hb_q_int_series = hb_q_int_model.historical_forecasts(
    hb_q_series,
    start=pd.Timestamp("20070630"),
    forecast_horizon=4,
    stride=1,
    retrain=False,
    verbose=True,
)
hud_q_int_pred_stop = time.time()
display_forecast(pred_hb_q_int_series, hb_q_series, "3-month", "N-BEATS Interpretable Model - Hudson Bay", start_date=pd.Timestamp("20070630"))
hud_q_int_mod_time = hud_q_int_mod_stop - hud_q_int_mod_start
hud_q_int_pred_time = hud_q_int_pred_stop - hud_q_int_pred_start
print("Train Time {}".format(hud_q_int_mod_time)+"s"+ "\nPrediction Time: {}".format(hud_q_int_pred_time)+"s")
